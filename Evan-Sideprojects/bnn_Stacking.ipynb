{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing BNN Stacking\n",
    "### Evan Edwards\n",
    "#### The Basic structure of this document is as follows:\n",
    "\n",
    "\n",
    "## Note: BNN for weight calculation still needs work \n",
    "\n",
    "\n",
    "#### Notes:\n",
    " - A simple BNN performs regression better than any of the created HLMS - (given these arbitrarily chosen input variables)\n",
    "    - May want to inquire on a hierarchial BNN to further improve predictions - aleady done, but stacking and use in large-scale clustered data is unseen\n",
    "    - A deep BNN performs very well, maybe also expirement with a hierarhcial structure - also use with mixing methods\n",
    "    - Still need to get credible intervals \n",
    " - Need to implement 90/10 cross-validation to test for generalization and overfitting\n",
    "\n",
    "\n",
    " #### Ideas\n",
    "  - Hierarchial BNNS exist already - maybe use an ensemble method on a collection of them?\n",
    "    - Maybe use them in a study similar to the PISA study\n",
    "  - Work on a sum of neural networks stacking model - \n",
    "    - w/ varying structures\n",
    "    - Still need to flesh out this idea\n",
    "    - Could also potentially be used for regression - very similar to random forest\n",
    "  - Use BART on hierarichal Deep BNNS - may yield accurate results, yet be costly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import bambi as bmb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "from scipy.stats import zscore\n",
    "from numpy import mean, std\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evan Edwards\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import torch.nn as nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from tqdm.auto import trange, tqdm\n",
    "from pyro.infer import MCMC, NUTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Taweret.mix.gaussian import Multivariate\n",
    "from Taweret.core.base_model import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed random seed to ensure reproducibility and the possiblility for optimization\n",
    "RANDOM_SEED = 9572404\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize data - z-score -> rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "PISA2018 = pd.read_csv(\"pisa2018.BayesBook.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evan Edwards\\AppData\\Local\\Temp\\ipykernel_10544\\2735236655.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  PISA2018['Female'] = PISA2018['Female'].replace({'Female': 1, 'Male': 0})\n"
     ]
    }
   ],
   "source": [
    "# Data processing: converting categorical values to numerical values\n",
    "PISA2018['Female'] = PISA2018['Female'].replace({'Female': 1, 'Male': 0})\n",
    "# Converting numerical to categorical values\n",
    "PISA2018['SchoolID'] = pd.Categorical(PISA2018['SchoolID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "PISA2018[\"PV1READ_unscaled\"] = PISA2018[\"PV1READ\"] \n",
    "PISA2018[\"PV1READ\"] = zscore(PISA2018[\"PV1READ\"])\n",
    "PISA2018_train, PISA2018_test = train_test_split(PISA2018, test_size=0.1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(pred, true):\n",
    "    rescaled_pred = pred * std(true) + mean(true)\n",
    "    return np.sqrt(np.sum(np.power(np.subtract(true, rescaled_pred),2))/len(true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [PV1READ_sigma, Intercept, Female, ESCS, HOMEPOS, ICTRES, 1|SchoolID_sigma, 1|SchoolID_offset, ICTRES|SchoolID_sigma, ICTRES|SchoolID_offset]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:34&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 114 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for model 1 - train set is: 93.82698991880818\n",
      "CPU times: total: 25.5 s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV1READ ~ Female + ESCS + HOMEPOS + ICTRES + (1 + ICTRES | SchoolID)\n",
    "model1 = bmb.Model(\"PV1READ ~ Female + ESCS + HOMEPOS + ICTRES + (1 + ICTRES | SchoolID)\", PISA2018_train, categorical = [\"SchoolID\"])\n",
    "priors = {\"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=100),\n",
    "          \"Female\": bmb.Prior(\"Normal\", mu=0, sigma=10),\n",
    "          \"ESCS\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"ESCS\"]), sigma=np.std(PISA2018_train[\"ESCS\"])),\n",
    "          \"HOMEPOS\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"HOMEPOS\"]), sigma=100),\n",
    "          \"ICTRES\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"ICTRES\"]), sigma=np.std(PISA2018_train[\"ICTRES\"])),\n",
    "          \"1|SchoolID\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=100)),\n",
    "          \"ICTRES|SchoolID\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=100)),\n",
    "          \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)}\n",
    "model1.set_priors(priors = priors)\n",
    "\n",
    "trace1 = model1.fit(draws=2000, random_seed=RANDOM_SEED)\n",
    "\n",
    "post_pred1 = model1.predict(trace1,data = PISA2018_train, inplace=False).posterior[\"PV1READ_mean\"]\n",
    "mean_pred1 = np.array(post_pred1.mean(dim=[\"chain\", \"draw\"]))\n",
    "print(f'The RMSE for model 1 - train set is: {RMSE(mean_pred1, PISA2018_train[\"PV1READ_unscaled\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [PV1READ_sigma, Intercept, JOYREAD, PISADIFF, SCREADCOMP, SCREADDIFF, 1|SchoolID_sigma, 1|SchoolID_offset]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:11&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 90 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for model 2 - train set is: 85.96626975169873\n",
      "CPU times: total: 21.5 s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV1READ ~ JOYREAD + PISADIFF + SCREADCOMP + SCREADDIFF + (1|SchoolID)\n",
    "model2 = bmb.Model(\"PV1READ ~ JOYREAD + PISADIFF + SCREADCOMP + SCREADDIFF + (1|SchoolID)\", PISA2018_train, categorical = [\"SchoolID\"])\n",
    "\n",
    "priors = {\"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=100),\n",
    "          \"JOYREAD\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"JOYREAD\"]), sigma=np.std(PISA2018_train[\"JOYREAD\"])),\n",
    "          \"PISADIFF\": bmb.Prior(\"Normal\", mu=0, sigma=100),\n",
    "          \"SCREADCOMP\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"SCREADCOMP\"]), sigma=10),\n",
    "          \"SCREADDIFF\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"SCREADDIFF\"]), sigma=np.std(PISA2018_train[\"SCREADDIFF\"])),\n",
    "          \"1|SchoolID\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=100)),\n",
    "          \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)}\n",
    "model2.set_priors(priors = priors)\n",
    "\n",
    "trace2 = model2.fit(draws=2000, random_seed=RANDOM_SEED)\n",
    "\n",
    "post_pred2 = model2.predict(trace2,data = PISA2018_train, inplace=False).posterior[\"PV1READ_mean\"]\n",
    "mean_pred2 = np.array(post_pred2.mean(dim=[\"chain\", \"draw\"]))\n",
    "print(f'The RMSE for model 2 - train set is: {RMSE(mean_pred2, PISA2018_train[\"PV1READ_unscaled\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [PV1READ_sigma, Intercept, METASUM, GFOFAIL, MASTGOAL, SWBP, WORKMAST, ADAPTIVITY, COMPETE, 1|SchoolID_sigma, 1|SchoolID_offset]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:16&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 96 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for model 3 - train set is: 88.39194098260263\n",
      "CPU times: total: 23.2 s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV1READ ~ METASUM + GFOFAIL + MASTGOAL + SWBP + WORKMAST + ADAPTIVITY + COMPETE + (1|SchoolID)\n",
    "model3 = bmb.Model(\"PV1READ ~ METASUM + GFOFAIL + MASTGOAL + SWBP + WORKMAST + ADAPTIVITY + COMPETE + (1|SchoolID)\", PISA2018_train, categorical = [\"SchoolID\"])\n",
    "\n",
    "priors = {\"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=100),\n",
    "          \"METASUM\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"METASUM\"]), sigma=np.std(PISA2018_train[\"METASUM\"])),\n",
    "          \"GFOFAIL\": bmb.Prior(\"Normal\", mu=0, sigma=100),\n",
    "          \"MASTGOAL\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"MASTGOAL\"]), sigma=10),\n",
    "          \"SWBP\": bmb.Prior(\"Normal\", mu=0, sigma=100),\n",
    "          \"WORKMAST\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"WORKMAST\"]), sigma=10),\n",
    "          \"ADAPTIVITY\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"ADAPTIVITY\"]), sigma=100),\n",
    "          \"COMPETE\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"COMPETE\"]), sigma=np.std(PISA2018_train[\"COMPETE\"])),\n",
    "          \"1|SchoolID\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=100)),\n",
    "          \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)}\n",
    "model3.set_priors(priors = priors)\n",
    "\n",
    "trace3 = model3.fit(draws=2000, random_seed=RANDOM_SEED)\n",
    "\n",
    "post_pred3 = model3.predict(trace3,data = PISA2018_train, inplace=False).posterior[\"PV1READ_mean\"]\n",
    "mean_pred3 = np.array(post_pred3.mean(dim=[\"chain\", \"draw\"]))\n",
    "print(f'The RMSE for model 3 - train set is: {RMSE(mean_pred3, PISA2018_train[\"PV1READ_unscaled\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [PV1READ_sigma, Intercept, PERFEED, TEACHINT, BELONG, 1|SchoolID_sigma, 1|SchoolID_offset, TEACHINT|SchoolID_sigma, TEACHINT|SchoolID_offset]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:28&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 107 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for model 4 - train set is: 95.01608735134099\n",
      "CPU times: total: 23.8 s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV1READ ~ PERFEED + TEACHINT + BELONG + (1 + TEACHINT | SchoolID)\n",
    "model4 = bmb.Model(\"PV1READ ~ PERFEED + TEACHINT + BELONG + (1 + TEACHINT | SchoolID)\", PISA2018_train, categorical = [\"SchoolID\"])\n",
    "\n",
    "priors = {\"Intercept\": bmb.Prior(\"Normal\", mu=0, sigma=100),\n",
    "          \"PERFEED\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"PERFEED\"]), sigma=np.std(PISA2018_train[\"PERFEED\"])),\n",
    "          \"TEACHINT\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"TEACHINT\"]), sigma=np.std(PISA2018_train[\"TEACHINT\"])),\n",
    "          \"BELONG\": bmb.Prior(\"Normal\", mu=np.mean(PISA2018_train[\"BELONG\"]), sigma=100),\n",
    "          \"1|SchoolID\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=100)),\n",
    "          \"TEACHINT|SchoolID\": bmb.Prior(\"Normal\", mu=0, sigma=bmb.Prior(\"HalfNormal\", sigma=100)),\n",
    "          \"sigma\": bmb.Prior(\"HalfNormal\", sigma=10)}\n",
    "model4.set_priors(priors = priors)\n",
    "\n",
    "trace4 = model4.fit(draws=2000, random_seed=RANDOM_SEED)\n",
    "\n",
    "post_pred4 = model4.predict(trace4,data = PISA2018_train, inplace=False).posterior[\"PV1READ_mean\"]\n",
    "mean_pred4 = np.array(post_pred4.mean(dim=[\"chain\", \"draw\"]))\n",
    "print(f'The RMSE for model 4 - train set is: {RMSE(mean_pred4, PISA2018_train[\"PV1READ_unscaled\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.array([mean_pred1, mean_pred2, mean_pred3, mean_pred4])).float()\n",
    "y = torch.tensor(np.array(PISA2018_train[\"PV1READ\"])).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple BNN Definition, Used as an indivudal regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of standardised inputs for prediction, abritrarily chosen\n",
    "inputs_features = torch.tensor(np.array([zscore(PISA2018_train[\"Female\"]),zscore(PISA2018_train[\"ESCS\"]), zscore(PISA2018_train[\"HOMEPOS\"]), zscore(PISA2018_train[\"ICTRES\"])])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 400/400 [31:07,  4.67s/it, step size=2.48e-03, acc. prob=0.877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE (IS) is: 36.73967067068268\n"
     ]
    }
   ],
   "source": [
    "#https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/Bayesian_Neural_Networks/dl2_bnn_tut1_students_with_answers.html\n",
    "class BNNSimple(PyroModule):\n",
    "    def __init__(self, in_dim=len(inputs_features), out_dim=1, hid_dim=6, prior_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, in_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([out_dim, hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.reshape(-1, len(inputs_features))\n",
    "        x = self.activation(self.layer1(x))\n",
    "        mu = self.layer2(x).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.HalfNormal(10)) \n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return mu\n",
    "\n",
    "model = BNNSimple()\n",
    "nuts_kernel = NUTS(model, jit_compile=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=200)\n",
    "mcmc.run(inputs_features, y)    \n",
    "\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(X) \n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "print(f'The RMSE (IS) is: {RMSE(PISA2018_train[\"PV1READ_unscaled\"], y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are better than any individual HLM, may want to inquiry into a hierarchial model -> then use in stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep BNN Definition, Used as an individual regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 400/400 [40:06,  6.02s/it, step size=1.40e-03, acc. prob=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE (IS) is: 36.76303833717518\n"
     ]
    }
   ],
   "source": [
    "class BNNDEEP(PyroModule):\n",
    "    def __init__(self, in_dim=len(inputs_features), out_dim=1, hid_dim=6, n_hid_layers=2, prior_scale=10):\n",
    "        super().__init__()\n",
    " \n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.layer_sizes = [in_dim] + n_hid_layers * [hid_dim] + [out_dim]\n",
    "        layer_list = [PyroModule[nn.Linear](self.layer_sizes[idx - 1], self.layer_sizes[idx]) for idx in\n",
    "                      range(1, len(self.layer_sizes))]\n",
    "        self.layers = PyroModule[torch.nn.ModuleList](layer_list)\n",
    "\n",
    "        for layer_idx, layer in enumerate(self.layers):\n",
    "            layer.weight = PyroSample(dist.Normal(0., prior_scale).expand(\n",
    "                [self.layer_sizes[layer_idx + 1], self.layer_sizes[layer_idx]]).to_event(2))\n",
    "            layer.bias = PyroSample(dist.Normal(0., prior_scale).expand([self.layer_sizes[layer_idx + 1]]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.reshape(-1, len(inputs_features))\n",
    "        x = self.activation(self.layers[0](x))\n",
    "        for layer in self.layers[1:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        mu = self.layers[-1](x).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.HalfNormal(10))\n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return mu\n",
    "    \n",
    "\n",
    "model = BNNDEEP()\n",
    "nuts_kernel = NUTS(model, jit_compile=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=200)\n",
    "mcmc.run(inputs_features, y)\n",
    "\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(inputs_features)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "print(f'The RMSE (IS) is: {RMSE(PISA2018_train[\"PV1READ_unscaled\"], y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple BNN Definition, Used as a meta-learner - the model outputs are used as the BNN inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 400/400 [38:02,  5.71s/it, step size=3.51e-03, acc. prob=0.801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE (IS) is: 34.980526351430036\n"
     ]
    }
   ],
   "source": [
    "#https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/Bayesian_Neural_Networks/dl2_bnn_tut1_students_with_answers.html\n",
    "class BNN1(PyroModule):\n",
    "    def __init__(self, in_dim=4, out_dim=1, hid_dim=8, prior_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, in_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([out_dim, hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.reshape(-1, 4)\n",
    "        x = self.activation(self.layer1(x))\n",
    "        mu = self.layer2(x).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.HalfNormal(10))  # Infer the response noise\n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return mu\n",
    "\n",
    "model = BNN1()\n",
    "nuts_kernel = NUTS(model, jit_compile=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=200)\n",
    "mcmc.run(X, y)\n",
    "\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(X)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "print(f'The RMSE (IS) is: {RMSE(PISA2018_train[\"PV1MATH\"], y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep BNN Definition, Used as a meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/4 [12:34:20, ?it/s]s/it, step size=1.48e-03, acc. prob=0.781]\n",
      "Warmup:  50%|█████     | 10/20 [12:32:27, 4514.77s/it, step size=3.67e-04, acc. prob=0.898]\n",
      "Warmup:   0%|          | 0/4 [12:15:20, ?it/s]\n",
      "Warmup:   0%|          | 0/4 [12:15:19, ?it/s]\n",
      "Warmup:   0%|          | 0/4 [12:14:42, ?it/s]\n",
      "Warmup:   0%|          | 0/4 [12:12:03, ?it/s]\n",
      "Sample: 100%|██████████| 400/400 [51:11,  7.68s/it, step size=1.48e-03, acc. prob=0.788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE (IS) is: 35.11588520738445\n"
     ]
    }
   ],
   "source": [
    "class BNN2(PyroModule):\n",
    "    def __init__(self, in_dim=4, out_dim=1, hid_dim=6, n_hid_layers=3, prior_scale=10.):\n",
    "        super().__init__()\n",
    " \n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        self.layer_sizes = [in_dim] + n_hid_layers * [hid_dim] + [out_dim]\n",
    "        layer_list = [PyroModule[nn.Linear](self.layer_sizes[idx - 1], self.layer_sizes[idx]) for idx in\n",
    "                      range(1, len(self.layer_sizes))]\n",
    "        self.layers = PyroModule[torch.nn.ModuleList](layer_list)\n",
    "\n",
    "        for layer_idx, layer in enumerate(self.layers):\n",
    "            layer.weight = PyroSample(dist.Normal(0., prior_scale).expand(\n",
    "                [self.layer_sizes[layer_idx + 1], self.layer_sizes[layer_idx]]).to_event(2))\n",
    "            layer.bias = PyroSample(dist.Normal(0., prior_scale).expand([self.layer_sizes[layer_idx + 1]]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.reshape(-1, 4)\n",
    "        x = self.activation(self.layers[0](x))\n",
    "        for layer in self.layers[1:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        mu = self.layers[-1](x).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.HalfNormal(10.))\n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return mu\n",
    "    \n",
    "\n",
    "model = BNN2()\n",
    "nuts_kernel = NUTS(model, jit_compile=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=200)\n",
    "mcmc.run(X, y)\n",
    "\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(X)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "print(f'The RMSE (IS) is: {RMSE(PISA2018_train[\"PV1MATH\"], y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNNS Work better as individual regressors - at least w/ these tested configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN - Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 4/4 [00:00, 45.71it/s, step size=1.12e-01, acc. prob=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE (IS) is: 916.7573435729306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BNNSimpleStack(PyroModule):\n",
    "    def __init__(self, in_dim=4, out_dim=1, hid_dim=4, prior_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, out_dim)\n",
    "\n",
    "        self.weight_layer = nn.Linear(in_dim, in_dim, bias=False)\n",
    "\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, in_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim]).to_event(1))\n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([out_dim, hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([out_dim]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.reshape(-1, len(x))\n",
    "        x = self.activation(self.layer1(x))\n",
    "        weights = torch.softmax(self.weight_layer.weight, dim=1)\n",
    "        weighted_inputs = torch.matmul(x, weights.t())\n",
    "        mu = self.layer2(weighted_inputs).squeeze()\n",
    "        sigma = pyro.sample(\"sigma\", dist.HalfNormal(10)) \n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return mu\n",
    "\n",
    "model = BNNSimpleStack()\n",
    "nuts_kernel = NUTS(model, jit_compile=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2)\n",
    "mcmc.run(X, y)\n",
    "\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(X)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "print(f'The RMSE (IS) is: {RMSE(PISA2018_train[\"PV1MATH\"], y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 400/400 [9:49:38, 88.45s/it, step size=1.00e-03, acc. prob=0.897] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE (IS) is: 34.91980322421185\n"
     ]
    }
   ],
   "source": [
    "class BNNSimpleStack(PyroModule):\n",
    "    def __init__(self, in_dim=4, out_dim=1, hid_dim=6, prior_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, hid_dim)\n",
    "        self.layer3 = PyroModule[nn.Linear](hid_dim, in_dim)\n",
    "        self.weight_layer = PyroModule[nn.Linear](1, in_dim, bias=False)\n",
    "\n",
    "        self.weight_layer.weight = PyroSample(dist.Normal(0., prior_scale).expand([1, in_dim]).to_event(2))\n",
    "\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, in_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim]).to_event(1))\n",
    "        \n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim]).to_event(1))\n",
    "\n",
    "        self.layer3.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, hid_dim]).to_event(2))\n",
    "        self.layer3.bias = PyroSample(dist.Normal(0., prior_scale).expand([in_dim]).to_event(1))\n",
    "\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.reshape(-1, len(x))\n",
    "        x = self.activation(self.layer1(x))\n",
    "        x = self.activation(self.layer2(x))\n",
    "        x = self.activation(self.layer3(x)).squeeze()\n",
    "                            \n",
    "        weights = torch.softmax(self.weight_layer.weight, dim=1)\n",
    "        weighted_inputs = torch.matmul(x, weights.t())\n",
    "        mu = weighted_inputs.sum(dim=1)\n",
    "        sigma = pyro.sample(\"sigma\", dist.HalfNormal(10)) \n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return mu\n",
    "\n",
    "model = BNNSimpleStack()\n",
    "nuts_kernel = NUTS(model, jit_compile=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=200)\n",
    "mcmc.run(X, y)\n",
    "\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(X)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "print(f'The RMSE (IS) is: {RMSE(PISA2018_train[\"PV1MATH\"], y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the weight samples:\n",
      "tensor([[-0.2911,  1.5804, -0.7624, -0.5089]])\n",
      "Standard deviation of the weight samples:\n",
      "tensor([[0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2911,  1.5804, -0.7624, -0.5089]],\n",
       "\n",
       "        [[-0.2911,  1.5804, -0.7624, -0.5089]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = mcmc.get_samples()\n",
    "\n",
    "# Extract weights from the samples\n",
    "weight_samples = samples['weight_layer.weight']\n",
    "\n",
    "# Get the mean and standard deviation of the weight samples\n",
    "weight_mean = weight_samples.mean(dim=0)\n",
    "weight_std = weight_samples.std(dim=0)\n",
    "\n",
    "print(\"Mean of the weight samples:\")\n",
    "print(weight_mean)\n",
    "\n",
    "print(\"Standard deviation of the weight samples:\")\n",
    "print(weight_std)\n",
    "weight_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/80 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 80/80 [1:17:43, 58.29s/it, step size=7.37e-03, acc. prob=0.685]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE (IS) is: 79.52750780956471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BNNSimpleStack(PyroModule):\n",
    "    def __init__(self, in_dim=4, out_dim=1, hid_dim=6, prior_scale=10.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "        self.layer1 = PyroModule[nn.Linear](in_dim, hid_dim)\n",
    "        self.layer2 = PyroModule[nn.Linear](hid_dim, in_dim)\n",
    "        self.weight_layer = PyroModule[nn.Linear](in_dim, in_dim, bias=False)\n",
    "\n",
    "        self.weight_layer.weight = PyroSample(dist.Normal(0., prior_scale).expand([1, in_dim]).to_event(2))\n",
    "\n",
    "        self.layer1.weight = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim, in_dim]).to_event(2))\n",
    "        self.layer1.bias = PyroSample(dist.Normal(0., prior_scale).expand([hid_dim]).to_event(1))\n",
    "        \n",
    "        self.layer2.weight = PyroSample(dist.Normal(0., prior_scale).expand([in_dim, hid_dim]).to_event(2))\n",
    "        self.layer2.bias = PyroSample(dist.Normal(0., prior_scale).expand([in_dim]).to_event(1))\n",
    "\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.reshape(-1, len(x))\n",
    "        x = self.activation(self.layer1(x))\n",
    "        x = self.activation(self.layer2(x)).squeeze()\n",
    "                            \n",
    "        weights = torch.softmax(self.weight_layer.weight, dim=1)\n",
    "        weighted_inputs = torch.matmul(x, weights.t())\n",
    "        mu = weighted_inputs.sum(dim=1)\n",
    "        sigma = pyro.sample(\"sigma\", dist.HalfNormal(10))\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return weights\n",
    "\n",
    "model = BNNSimpleStack()\n",
    "nuts_kernel = NUTS(model, jit_compile=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=40)\n",
    "mcmc.run(X, y)\n",
    "\n",
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(X)\n",
    "\n",
    "y_pred = preds['obs'].T.detach().numpy().mean(axis=1)\n",
    "y_std = preds['obs'].T.detach().numpy().std(axis=1)\n",
    "print(f'The RMSE (IS) is: {RMSE(PISA2018_train[\"PV1MATH\"], y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BNN - Weighting by Variance - WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum-of Neural Networks Model - WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking with Taweret - Multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking with Taweret (BART) - WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
