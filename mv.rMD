---
author: "Evan Edwards"
title: "p-BMA"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message  =FALSE,
                      error = TRUE, fig.height = 4)
library(reticulate)
use_python("C:/anaconda3/python.exe")
py_available(TRUE)
```


```{r}
BaseModel <- import("Taweret.core.base_model")$BaseModel
plt <- import("matplotlib.pyplot", convert = TRUE)
np <- import("numpy", convert = TRUE)
pd <- import("pandas", convert = TRUE)
mean_squared_error <- import("sklearn.metrics", convert = TRUE)$mean_squared_error
Multivariate <- import("Taweret.mix.gaussian", convert = TRUE)$Multivariate
sqrt <- import("math", convert = TRUE)$sqrt
az <- import("arviz", convert = TRUE)
logging <- import("logging", convert = TRUE)
bmb <- import("bambi", convert = TRUE)
pm <- import("pymc", convert = TRUE)
scipy <- import("scipy", convert = TRUE)
time <- import("time", convert = TRUE)

# Fixed random seed to ensure reproducibility and the possibility for optimization
RANDOM_SEED <- 9572404L
np$random$seed(RANDOM_SEED)

# Defining to disable output later for ease of visibility
logger <- logging$getLogger("pymc")
# Disabling sampling messages
logger$setLevel(logging$ERROR)

# Load dataset
PISA2018 <- pd$read_csv("pisa2018.BayesBook.csv")
# Data processing: converting categorical values to numerical values
PISA2018[["Female"]] <- ifelse(PISA2018[["Female"]] == "Female", 1.0, 0.0)
# Converting numerical to categorical values
PISA2018[["SchoolID"]] <- as.numeric(as.factor(PISA2018[["SchoolID"]]))

variables <- c("Female", "ESCS", "METASUM", "PERFEED", "HOMEPOS", "ADAPTIVITY", 
                "TEACHINT", "ICTRES", "JOYREAD", "ATTLNACT", "COMPETE", "WORKMAST", 
                "GFOFAIL", "SWBP", "MASTGOAL", "BELONG", "SCREADCOMP", "SCREADDIFF", 
                "PISADIFF", "PV1READ", "SchoolID")

PISA2018 <- PISA2018[, variables]


# Generate a vector of row indices
num_rows <- nrow(PISA2018)
train_indices <- sample(1:num_rows, 0.9 * num_rows)
validation_indices <- setdiff(1:num_rows, train_indices)

# Create training and validation sets
train_set <- PISA2018[train_indices, ]
validation_set <- PISA2018[validation_indices, ]

```

```{python}

```

```{python}
#PV1READ ~ Female + ESCS + HOMEPOS + ICTRES + (1 + ICTRES | SchoolID)
start_time = r.time.time()
model1 = r.bmb.Model("PV1READ ~ Female + ESCS + HOMEPOS + ICTRES + (1 + ICTRES | SchoolID)", r.train_set, categorical = ["SchoolID"])
priors = {"Intercept": r.bmb.Prior("Normal", mu=0, sigma=100),
          "Female": r.bmb.Prior("Normal", mu=0, sigma=10),
          "ESCS": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["ESCS"]), sigma=r.np.std(r.train_set["ESCS"])),
          "HOMEPOS": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["HOMEPOS"]), sigma=100),
          "ICTRES": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["ICTRES"]), sigma=r.np.std(r.train_set["ICTRES"])),
          "1|SchoolID": r.bmb.Prior("Normal", mu=0, sigma=r.bmb.Prior("HalfNormal", sigma=100)),
          "ICTRES|SchoolID": r.bmb.Prior("Normal", mu=0, sigma=r.bmb.Prior("HalfNormal", sigma=100)),
          "sigma": r.bmb.Prior("HalfNormal", sigma=10)}
model1.set_priors(priors = priors)

trace1 = model1.fit(draws=2000, random_seed=r.RANDOM_SEED)

post_pred1 = model1.predict(trace1,data = r.validation_set, inplace=False, sample_new_groups = True).posterior["PV1READ_mean"]
mean_pred = r.np.array(post_pred1.mean(dim=["chain", "draw"]))
print('The RMSE for model 1 - PV1READ ~ Female + ESCS + HOMEPOS + ICTRES + (1 + ICTRES | SchoolID) is:'  + str(r.sqrt(r.mean_squared_error(r.validation_set["PV1READ"], mean_pred))))


end_time = r.time.time()
elapsed_time = end_time - start_time

print(elapsed_time)
```

```{python}
#PV1READ ~ JOYREAD + PISADIFF + SCREADCOMP + SCREADDIFF + (1|SchoolID)
start_time = r.time.time()
model2 = r.bmb.Model("PV1READ ~ JOYREAD + PISADIFF + SCREADCOMP + SCREADDIFF + (1|SchoolID)", r.train_set, categorical = ["SchoolID"])

priors = {"Intercept": r.bmb.Prior("Normal", mu=0, sigma=100),
          "JOYREAD": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["JOYREAD"]), sigma=r.np.std(r.train_set["JOYREAD"])),
          "PISADIFF": r.bmb.Prior("Normal", mu=0, sigma=100),
          "SCREADCOMP": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["SCREADCOMP"]), sigma=10),
          "SCREADDIFF": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["SCREADDIFF"]), sigma=r.np.std(r.train_set["SCREADDIFF"])),
          "1|SchoolID": r.bmb.Prior("Normal", mu=0, sigma=r.bmb.Prior("HalfNormal", sigma=100)),
          "sigma": r.bmb.Prior("HalfNormal", sigma=10)}
model2.set_priors(priors = priors)

trace2 = model2.fit(draws=2000, random_seed=r.RANDOM_SEED)

post_pred2 = model2.predict(trace2, data = r.validation_set, inplace=False, sample_new_groups = True).posterior["PV1READ_mean"]
mean_pred = r.np.array(post_pred2.mean(dim=["chain", "draw"]))
print(f'The RMSE for model 2 - PV1READ ~ JOYREAD + PISADIFF + SCREADCOMP + SCREADDIFF + (1|SchoolID) is: {r.sqrt(r.mean_squared_error(r.validation_set["PV1READ"], mean_pred))}')

end_time = r.time.time()
elapsed_time = end_time - start_time

print(f"Computation time: {elapsed_time} seconds")
```

```{python}
#PV1READ ~ METASUM + GFOFAIL + MASTGOAL + SWBP + WORKMAST + ADAPTIVITY + COMPETE + (1|SchoolID)
start_time = r.time.time()
model3 = r.bmb.Model("PV1READ ~ METASUM + GFOFAIL + MASTGOAL + SWBP + WORKMAST + ADAPTIVITY + COMPETE + (1|SchoolID)", r.train_set, categorical = ["SchoolID"])

priors = {"Intercept": r.bmb.Prior("Normal", mu=0, sigma=100),
          "METASUM": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["METASUM"]), sigma=r.np.std(r.train_set["METASUM"])),
          "GFOFAIL": r.bmb.Prior("Normal", mu=0, sigma=100),
          "MASTGOAL": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["MASTGOAL"]), sigma=10),
          "SWBP": r.bmb.Prior("Normal", mu=0, sigma=100),
          "WORKMAST": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["WORKMAST"]), sigma=10),
          "ADAPTIVITY": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["ADAPTIVITY"]), sigma=100),
          "COMPETE": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["COMPETE"]), sigma=r.np.std(r.train_set["COMPETE"])),
          "1|SchoolID": r.bmb.Prior("Normal", mu=0, sigma=r.bmb.Prior("HalfNormal", sigma=100)),
          "sigma": r.bmb.Prior("HalfNormal", sigma=10)}
model3.set_priors(priors = priors)
 
trace3 = model3.fit(draws=2000, random_seed=r.RANDOM_SEED)

post_pred3 = model3.predict(trace3, data = r.validation_set, inplace=False, sample_new_groups = True).posterior["PV1READ_mean"]
mean_pred = r.np.array(post_pred3.mean(dim=["chain", "draw"]))
print(f'The RMSE for model 3 - PV1READ ~ METASUM + GFOFAIL + MASTGOAL + SWBP + WORKMAST + ADAPTIVITY + COMPETE + (1|SchoolID) is: {r.sqrt(r.mean_squared_error(r.validation_set["PV1READ"], mean_pred))}')


end_time = r.time.time()
elapsed_time = end_time - start_time

print(f"Computation time: {elapsed_time} seconds")
```

```{python}
#PV1READ ~ PERFEED + TEACHINT + BELONG + (1 + TEACHINT | SchoolID)
start_time = r.time.time()
model4 = r.bmb.Model("PV1READ ~ PERFEED + TEACHINT + BELONG + (1 + TEACHINT | SchoolID)", r.train_set, categorical = ["SchoolID"])

priors = {"Intercept": r.bmb.Prior("Normal", mu=0, sigma=100),
          "PERFEED": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["PERFEED"]), sigma=r.np.std(r.train_set["PERFEED"])),
          "TEACHINT": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["TEACHINT"]), sigma=r.np.std(r.train_set["TEACHINT"])),
          "BELONG": r.bmb.Prior("Normal", mu=r.np.mean(r.train_set["BELONG"]), sigma=100),
          "1|SchoolID": r.bmb.Prior("Normal", mu=0, sigma=r.bmb.Prior("HalfNormal", sigma=100)),
          "TEACHINT|SchoolID": r.bmb.Prior("Normal", mu=0, sigma=r.bmb.Prior("HalfNormal", sigma=100)),
          "sigma": r.bmb.Prior("HalfNormal", sigma=10)}
model4.set_priors(priors = priors)

trace4 = model4.fit(draws=2000, random_seed=r.RANDOM_SEED)

post_pred4 = model4.predict(trace4, data = r.validation_set, inplace=False, sample_new_groups = True).posterior["PV1READ_mean"]
mean_pred = r.np.array(post_pred4.mean(dim=["chain", "draw"]))
print(f'The RMSE for model 4 - PV1READ ~ PERFEED + TEACHINT + BELONG + (1 + TEACHINT | SchoolID) is: {r.sqrt(r.mean_squared_error(r.validation_set["PV1READ"], mean_pred))}')

end_time = r.time.time()
elapsed_time = end_time - start_time

print(f"Computation time: {elapsed_time} seconds")
```

```{python}
# A wrapper class for the Bambi/PYMC models to be compatible with the Taweret framework
class BMBWrapper(r.BaseModel):
    def __init__(self, model, idata, posterior_predictive):
        self.model = model
        self.idata = idata
        self.posterior_predictive = posterior_predictive
        
    def evaluate(self, model_parameters):
        post_pred = self.model.predict(self.idata, data = model_parameters, inplace=False).posterior[self.posterior_predictive]
        return r.np.array(post_pred.mean(dim=["chain", "draw"])).reshape(-1, 1), r.np.sqrt(r.np.array(post_pred.var(dim=["chain", "draw"]))).flatten().reshape(-1, 1)

    
    def log_likelihood_elementwise(self,x_exp, y_exp, y_err, model_params):
        y = self.evaluate(model_params)[0]
        
        return r.np.exp(-(y - y_exp) **2 / (2 * y_err ** 2)) \
            / r.np.sqrt(2 * r.np.pi * y_err ** 2)
    
    def set_prior(self, prior_dict):
        self.model.set_priors(priors=prior_dict)

```

```{python}
# Using the multivariate mixer to combine the four models in a gaussian form

# Defining a dictionary of the models
models = {
            "1": BMBWrapper(model1, trace1, "PV1READ_mean"),
            "2": BMBWrapper(model2, trace2, "PV1READ_mean"),
            "3": BMBWrapper(model3, trace3, "PV1READ_mean"),
            "4": BMBWrapper(model4, trace4, "PV1READ_mean")
}
start_time = r.time.time()
# The multivariate model
multivariate_mixer = r.Multivariate(r.validation_set, models)
# Gather predictions and calculate the RMSE score
draws, mean, intervals, std_dev = multivariate_mixer.predict(ci=95)
end_time = r.time.time()
elapsed_time = end_time - start_time

print(f"Computation time: {elapsed_time} seconds")


print(f'The RMSE score of the mixer: {((r.sqrt(r.mean_squared_error(r.validation_set["PV1READ"], mean))))}')
```
